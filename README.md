# LLM-RL-Papers

## MARL in LLMs
* Large language model based multi-agents: A survey of progress and challenges. [Paper](https://arxiv.org/pdf/2402.01680) by Guo, Taicheng, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, and Xiangliang Zhang. 2024.
* Theory of mind for multi-agent collaboration via large language models [Paper](https://arxiv.org/pdf/2310.10701) by Li, Huao, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Michael Lewis, and Katia Sycara. 2023.

## Reward 
* **LLM-Reward**: "Language to Rewards for Robotic Skill Synthesis", *arXiv, Jun 2023*. [[Paper](https://arxiv.org/abs/2306.08647)] [[Website](https://language-to-reward.github.io/)]

* **ELLM**: "Guiding Pretraining in Reinforcement Learning with Large Language Models", *arXiv, Sep 2023*. [[Paper](https://arxiv.org/abs/2302.06692)] [[Website](https://github.com/yuqingd/ellm.)]

* **LAMP**: "Language Reward Modulation for Pretraining Reinforcement Learning", *arXiv, Aug 2023*. [[Paper](https://arxiv.org/abs/2308.12270)] [[Website](https://github.com/ademiadeniji/lamp)]
* **Text2Reward**: "Text2Reward: Automated Dense Reward Function Generation for Reinforcement Learning", *arXiv, Sep 2023*. [[Paper](https://arxiv.org/abs/2309.11489)] [[Website](https://text-to-reward.github.io/)]
* **Reflexion**: "Reflexion: Language Agents with Verbal Reinforcement Learning", *arXiv, Sep 2023*. [[Paper](https://arxiv.org/abs/2303.11366)] [[Website](https://github.com/noahshinn/reflexion)]


## Manipulation
* **RoboCat**: "RoboCat: A Self-Improving Foundation Agent for Robotic Manipulation", *arxiv, Oct 2023*. [[Paper](https://arxiv.org/pdf/2303.11366.pdf)]  [[Website](https://www.deepmind.com/blog/robocat-a-self-improving-robotic-agent)]

* **WHEN2ASK**: "Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach", *arxiv, Aug 2023*. [[Paper](https://arxiv.org/abs/2306.03604)]  [[Website](https://github.com/ZJLAB-AMMI/LLM4RL)]

* **Plan4MC**: "Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks", *arxiv, Mar 2023*. [[Paper](https://arxiv.org/abs/2303.16563)]  [[Website](https://sites.google.com/view/plan4mc)]

* **LgTS**: "LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents", *arxiv, Oct 2023*. [[Paper](https://arxiv.org/abs/2310.09454)] 

* **RLAdapter**: "RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds", *arxiv, Sep 2023*. [[Paper](https://arxiv.org/abs/2309.17176)]  

* **Motif**: "Motif: Intrinsic Motivation from Artificial Intelligence Feedback", *arxiv, Mar 2023*. [[Paper](https://arxiv.org/abs/2310.00166)]

* **LaGR-SEQ**: "LaGR-SEQ: Language-Guided Reinforcement Learning with Sample-Efficient Querying", *arxiv, Aug 2023*. [[Paper](https://arxiv.org/abs/2308.13542)]  [[Website](https://github.com/GKthom/LaGRSEQ)]

## Instruction
* **MILLION**: "Meta-Reinforcement Learning via Language Instructions", *arXiv, Sep 2022*. [[Paper](https://arxiv.org/abs/2209.04924)] [[Website](https://tumi6robot.wixsite.com/million)]

* **instructRL**: "Language Instructed Reinforcement Learning for Human-AI Coordination", *arXiv, Jun 2023*. [[Paper](https://arxiv.org/abs/2304.07297)] [[Website](https://github.com/hengyuan-hu/instruct-rl)]

* **Dialogue Shaping**: "Dialogue Shaping: Empowering Agents through NPC Interaction", *arXiv, Jun 2023*. [[Paper](https://arxiv.org/abs/2307.15833)] 

* "Towards A Unified Agent with Foundation Models", *arXiv, Jun 2023*. [[Paper](https://arxiv.org/abs/2307.09668)] 

## Policy
* **GLAM**: "Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning", *arXiv, Sep 2023*. [[Paper](https://arxiv.org/abs/2302.02662)] [[Website](https://github.com/flowersteam/Grounding_LLMs_with_online_RL)]

